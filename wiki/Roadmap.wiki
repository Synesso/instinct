#summary Instinct Roadmap
#labels Featured

= Implementation Plan =
  # ~~Build infrastructure~~
    # ~~Code coverage~~
    # Artifacts
  # ~~TeamCity integration~~
  # ~~Implement core annotations (context, specification)~~
  # ~~Implement suite aggregator~~
  # ~~Get example code working~~
  # ~~Figure out mocking implementation to use~~
  # Auto mocking (dummies, stubs & mocks)
    # Mock discovery
    # Dummy creation
    # Stub creation
    # Mock creation
  # Test coverage to 100%
  # Retrofit Assert.assertX() in tests to use Hamcrest style assertions
  # Auto unique field creation (are these just dummies?)
  # Auto fixture/subject creation
  # Add naming conventions to all locators
  # ~~Come up with nomenclature (see terms.txt)~~
  # Verification classes (Hamcrest?)
    # JUnit Assert feature parity
    # Boost's assertThrows
  # Auto discovery of naming conventions at runtime
  # IntelliJ Plugin
  # Ant runner
  # Revisit distribution mechanism, perhaps an all, src, what about dependencies?
  # ~~Add source to distribution Jar~~
  # Produce Javadoc Jar as part of artifacts

= Markers =

How do you find things? Specifications, contexts, mocks, etc.

  * Naming conventions
  * Marker interfaces
  * ~~Annotations~~
  * Method signatures - "public void ...()" for classes in the test tree for example

== Annotations ==

  * ~~Use @BehaviourContext annotation to denote context classes.~~
  * Include an @Fixture annotation to support auto creation of fixtures where able to.
    * If fixtures depend on mocks, use the mock types where possible
    * Perhaps have conditions places on the fixtures to denote how they should be created @Fixture(dependencies=AUTO_MOCK,AUTO_UNIQUE)
  * Do we even need behaviour context markers? Surely we can just find the classes containing specifications and execute them (with currently implemented checks)
  * Add a "description" attribute to the BehaviourContext annotation, to give a description to use when reporting (errors, reports, documentation, etc.)

== Naming Conventions ==
  * Unique fields (also want to be able to specify conditions, e.g. positive int, ranges, etc.)
  * Mocked fields (a mock that is verified)
  * Stub fields (just an instance)
  * Fixtures

= Integration =

  * IntelliJ IDEA plugin
  * Eclipse plugin?
  * Ant support
  * Maven plugin (or SureFire integration)
  * ~~Support for JUnit runners.~~

= Testing =

  * ~~Allow/encourage more than one Context per class file~~
  * Provide UniqueTestUtil functionality, @Unique annotation & naming convention (are these just dummies?)
  * Create a Verify class similar to Assert. This will allow static access to the checks (so that this just becomes a wrapper). Probably use [http://code.google.com/p/hamcrest/ Hamcrest] to do this.
  * ~~Context classes should not need to have a suffix "Context".~~
  * Provide closure style assertThrows checks.
  * Support grouping of contexts
    * Via annotation
    * Via marker interfaces, allow extension of base marker interfaces to define new groups
    * Add this into Ant support as option on aggregators (i.e. name of group to run)
    * Add this into IntelliJ plugin, perhaps as an option in run dialog
    * Does it make sense to add this to the BehaviourContext annotation or specification annotation like TestNG?

= Mocking =

  * Bundle a mocking library - probably JMock
  * Create automocker - dummies, stubs & mocks
    * Support automocking using an annotation (@Mock) and naming convention
    * Fields for automocking will require annotation or naming convention (& currently hold null value?)
  * Mock role names should be discovered by using the name of the field (in addition to standard JMock method).
  * ~~Possibly allow different mock types - nice, stubs, etc.~~
  * Should allow mocking to be done automatically or manually. Manual mocking should be explicitly allowed.
  * ~~Expose Mocker via static utility, should have the same hooks into the lifecycle (e.g. verification) as auto mocked fields.~~
  * Implementations ideas:
    * Use JMock style DSL. Wrap JMock classes thinly.
    * Perhaps allow plugable mocking implementations?

= Aggregation =
  * ~~Hook into junit style runners for IDE integration~~
  * IntelliJ plugin to run tests individually (look at code from TestNG plugin - http://code.google.com/p/testng-idea/).

= Functionality =
  * ~~Allow "naming conventions" to be added~~ (discover these at runtime to extend functionality).
  * Need some way to discover what methods to run for non-annotated classes. Provide a naming convention to do this.
  * ~~For classes with annotations, may not want to also add in specification methods discovered by naming conventions.~~

= Test Strategy =
  * Determine how to automatically test core code against example code (maybe seperate classloader). This could form a  "compatibility" suite.

= Implementation Details =

  * Do we need to create a new instance of the context class for each specification method?

= Documentation =

  * Describe (using an Ant build) how to use the Ant runner with system properties to only run a build on a CI server (for example), or some other conditions